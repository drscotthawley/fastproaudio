---

title: End-to-End Time Domain Audio with fastai


keywords: fastai
sidebar: home_sidebar



nb_path: "01_td_demo.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_td_demo.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">import</span> <span class="nn">torchaudio.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchaudio.transforms</span> <span class="k">as</span> <span class="nn">T</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Audio</span> 

<span class="kn">from</span> <span class="nn">fastproaudio.core</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">use_fastaudio</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">use_fastaudio</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">fastaudio.core.all</span> <span class="kn">import</span> <span class="o">*</span>
    <span class="kn">from</span> <span class="nn">fastaudio.augment.all</span> <span class="kn">import</span> <span class="o">*</span>
    <span class="kn">from</span> <span class="nn">fastaudio.ci</span> <span class="kn">import</span> <span class="n">skip_if_ci</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As for data, we just use the fastaudio "speakers" dataset for now:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#path = untar_data(URLs.SPEAKERS10)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>....and then we could learn some kind of inverse effect such as denoising: we could add noise to the audio files and then train the network to remove the noise.</p>
<p>But what other audio datasets are available?</p>
<ul>
<li><a href="https://pytorch.org/audio/stable/datasets.html">torchaudio datasets</a>. These are almost all about speech; only GTZAN is musical.  </li>
<li>I've got the <a href="https://zenodo.org/record/3824876">SignalTrain audio dataset for compressors</a> although it's 20 GB. </li>
<li><a href="https://source-separation.github.io/tutorial/data/datasets.html">Source separation datasets</a>, i.e. mono-to-many</li>
<li><a href="https://ismir.net/resources/datasets/">ISMIR has a list of datasets</a></li>
<li>We can always grab audio and then use Spotify's new <a href="https://github.com/spotify/pedalboard">Pedalboard</a> to add effects</li>
<li><a href="https://zenodo.org/record/3562442">Marco Martinez' Leslie effects dataset</a> is a bit less than 1 GB. It has "dry" (input) and "tremelo" (target) directories.</li>
</ul>
<p>Since Christian Steinmetz uses SignalTrain data for his <a href="https://github.com/csteinmetz1/micro-tcn">Micro-TCN</a>, we'll do that, using the 200MB "Reduced" version I just made:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">get_audio_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">SIGNALTRAIN_LA2A_REDUCED</span><span class="p">);</span> <span class="n">path</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Path(&#39;/home/shawley/.fastai/data/SignalTrain_LA2A_Reduced&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Steinmetz uses PyTorch Lightning instead of fastai.  We should be able to do the bare minimum integration by following Zach Mueller's prescription.</p>

</div>
</div>
</div>
</div>
 

